import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

/**
 * Generates a new logo based on input images and a text prompt.
 * Uses the 'gemini-2.5-flash-image' model (Nano banana).
 */
export const generateLogo = async (
  logoBase64: string,
  fontBase64: string | null,
  prompt: string
): Promise<string> => {
  try {
    const parts: any[] = [];

    // 1. Add the main logo to edit
    parts.push({
      inlineData: {
        mimeType: 'image/png', // Assuming PNG/JPEG, API handles detection usually, but explicit is good
        data: logoBase64,
      },
    });

    // 2. Add the font reference if provided
    if (fontBase64) {
      parts.push({
        inlineData: {
          mimeType: 'image/png',
          data: fontBase64,
        },
      });
      // Add context about the second image to the prompt
      prompt = `${prompt} (Use the second image as a strict reference for the font style/typography of the text 'ANA SHARIF').`;
    }

    // 3. Add the text prompt
    parts.push({
      text: prompt,
    });

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: parts,
      },
      config: {
        // No responseMimeType for this model
      }
    });

    // Extract image from response
    // The response might contain text and/or images. We look for the image part.
    if (response.candidates && response.candidates[0].content.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
          const base64Data = part.inlineData.data;
          return `data:image/png;base64,${base64Data}`;
        }
      }
    }

    throw new Error("No image generated by the model.");

  } catch (error: any) {
    console.error("Gemini API Error:", error);
    throw new Error(error.message || "Failed to generate logo");
  }
};